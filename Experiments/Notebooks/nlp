{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nlp","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"YETQHUqZROfx","colab_type":"code","outputId":"a96f5fb4-eb57-497f-edf6-d51c5b480fe3","executionInfo":{"status":"error","timestamp":1571231088670,"user_tz":-480,"elapsed":5931,"user":{"displayName":"Gan Jun Ying","photoUrl":"","userId":"05573927932906742162"}},"colab":{"base_uri":"https://localhost:8080/","height":368}},"source":["import argparse\n","import os\n","import sys\n","import time\n","import math\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","\n","\n","from fp16 import FP16_Module, FP16_Optimizer\n","\n","import data\n","import model\n","from model import DistributedDataParallel as DDP\n","\n","from apex.reparameterization import apply_weight_norm, remove_weight_norm\n","from configure_data import configure_data\n","from learning_rates import LinearLR\n","\n","parser = argparse.ArgumentParser(description='PyTorch Sentiment-Discovery Language Modeling')\n","parser.add_argument('--model', type=str, default='mLSTM',\n","                    help='type of recurrent net (Tanh, ReLU, LSTM, mLSTM, GRU)')\n","parser.add_argument('--emsize', type=int, default=64,\n","                    help='size of word embeddings')\n","parser.add_argument('--nhid', type=int, default=4096,\n","                    help='number of hidden units per layer')\n","parser.add_argument('--nlayers', type=int, default=1,\n","                    help='number of layers')\n","parser.add_argument('--lr', type=float, default=5e-4,\n","                    help='initial learning rate')\n","parser.add_argument('--constant_decay', type=int, default=None,\n","                    help='number of iterations to decay LR over,' + \\\n","                         ' None means decay to zero over training')\n","parser.add_argument('--clip', type=float, default=0,\n","                    help='gradient clipping')\n","parser.add_argument('--epochs', type=int, default=1,\n","                    help='upper epoch limit')\n","parser.add_argument('--dropout', type=float, default=0.0,\n","                    help='dropout applied to layers (0 = no dropout)')\n","parser.add_argument('--tied', action='store_true',\n","                    help='tie the word embedding and softmax weights')\n","parser.add_argument('--seed', type=int, default=1234,\n","                    help='random seed')\n","parser.add_argument('--log-interval', type=int, default=100, metavar='N',\n","                    help='report interval')\n","parser.add_argument('--save', type=str,  default='lang_model.pt',\n","                    help='path to save the final model')\n","parser.add_argument('--load', type=str, default='',\n","                    help='path to a previously saved model checkpoint')\n","parser.add_argument('--load_optim', action='store_true',\n","                    help='load most recent optimizer to resume training')\n","parser.add_argument('--save_iters', type=int, default=2000, metavar='N',\n","                    help='save current model progress interval')\n","parser.add_argument('--save_optim', action='store_true',\n","                    help='save most recent optimizer')\n","parser.add_argument('--fp16', action='store_true',\n","                    help='Run model in pseudo-fp16 mode (fp16 storage fp32 math).')\n","parser.add_argument('--dynamic_loss_scale', action='store_true',\n","                    help='Dynamically look for loss scalar for fp16 convergance help.')\n","parser.add_argument('--no_weight_norm', action='store_true',\n","                    help='Add weight normalization to model.')\n","parser.add_argument('--loss_scale', type=float, default=1,\n","                    help='Static loss scaling, positive power of 2 values can improve fp16 convergence.')\n","parser.add_argument('--world_size', type=int, default=1,\n","                    help='number of distributed workers')\n","parser.add_argument('--distributed_backend', default='gloo',\n","                    help='which backend to use for distributed training. One of [gloo, nccl]')\n","parser.add_argument('--rank', type=int, default=-1,\n","                    help='distributed worker rank. Typically set automatically from multiproc.py')\n","parser.add_argument('--base-gpu', type=int, default=0,\n","                    help='base gpu to use as gpu 0')\n","parser.add_argument('--optim', default='Adam',\n","                    help='One of PyTorch\\'s optimizers (Adam, SGD, etc). Default: Adam')\n","parser.add_argument('--tcp-port', type=int, default=6000,\n","                   help='tcp port so as to avoid address already in use errors')\n","\n","# Add dataset args to argparser and set some defaults\n","data_config, data_parser = configure_data(parser)\n","data_config.set_defaults(data_set_type='L2R', transpose=True)\n","data_parser.set_defaults(split='100,1,1')\n","data_parser = parser.add_argument_group('language modeling data options')\n","data_parser.add_argument('--seq_length', type=int, default=256,\n","                         help=\"Maximum sequence length to process (for unsupervised rec)\")\n","data_parser.add_argument('--eval_seq_length', type=int, default=256,\n","                         help=\"Maximum sequence length to process for evaluation\")\n","data_parser.add_argument('--lazy', action='store_true',\n","                         help='whether to lazy evaluate the data set')\n","data_parser.add_argument('--persist_state', type=int, default=1,\n","                         help='0=reset state after every sample in a shard, 1=reset state after every shard, -1=never reset state')\n","data_parser.add_argument('--num_shards', type=int, default=102,\n","                         help=\"\"\"number of total shards for unsupervised training dataset. If a `split` is specified,\n","                                 appropriately portions the number of shards amongst the splits.\"\"\")\n","data_parser.add_argument('--val_shards', type=int, default=0,\n","                         help=\"\"\"number of shards for validation dataset if validation set is specified and not split from training\"\"\")\n","data_parser.add_argument('--test_shards', type=int, default=0,\n","                         help=\"\"\"number of shards for test dataset if test set is specified and not split from training\"\"\")\n","data_parser.add_argument('--train-iters', type=int, default=1000,\n","                        help=\"\"\"number of iterations per epoch to run training for\"\"\")\n","data_parser.add_argument('--eval-iters', type=int, default=100,\n","                        help=\"\"\"number of iterations per epoch to run validation/test for\"\"\")\n","\n","args = parser.parse_args()\n","\n","torch.backends.cudnn.enabled = False\n","args.cuda = torch.cuda.is_available()\n","\n","# initialize distributed process group and set device\n","if args.rank > 0 or args.base_gpu != 0:\n","    torch.cuda.set_device((args.rank+args.base_gpu) % torch.cuda.device_count())\n","\n","if args.world_size > 1:\n","    distributed_init_file = os.path.splitext(args.save)[0]+'.distributed.dpt'\n","    torch.distributed.init_process_group(backend=args.distributed_backend, world_size=args.world_size,\n","                                         init_method='tcp://localhost:{}'.format(args.tcp_port), rank=args.rank)\n","#                                                    init_method='file://'+distributed_init_file, rank=args.rank)\n","\n","# Set the random seed manually for reproducibility.\n","if args.seed > 0:\n","    torch.manual_seed(args.seed)\n","    if args.cuda:\n","        torch.cuda.manual_seed(args.seed)\n","\n","if args.loss_scale != 1 and args.dynamic_loss_scale:\n","    raise RuntimeError(\"Static loss scale and dynamic loss scale cannot be used together.\")\n","\n","###############################################################################\n","# Load data\n","###############################################################################\n","\n","# Starting from sequential data, the unsupervised dataset type loads the corpus\n","# into rows. With the alphabet as the our corpus and batch size 4, we get\n","# ┌ a b c d e f ┐\n","# │ g h i j k l │\n","# │ m n o p q r │\n","# └ s t u v w x ┘.\n","# These rows are treated as independent by the model, which means that the\n","# dependence of e. g. 'g' on 'f' can not be learned, but allows more efficient\n","# batch processing.\n","#\n","# The unsupervised dataset further splits the corpus into shards through which\n","# the hidden state is persisted. The dataset also produces a hidden state\n","# reset mask that resets the hidden state at the start of every shard. A valid\n","# mask might look like\n","# ┌ 1 0 0 0 0 0 ... 0 0 0 1 0 0 ... ┐\n","# │ 1 0 0 0 0 0 ... 0 1 0 0 0 0 ... │\n","# │ 1 0 0 0 0 0 ... 0 0 1 0 0 0 ... │\n","# └ 1 0 0 0 0 0 ... 1 0 0 0 0 0 ... ┘.\n","# With 1 indicating to reset hidden state at that particular minibatch index\n","(train_data, val_data, test_data), tokenizer = data_config.apply(args)\n","\n","###############################################################################\n","# Build the model\n","###############################################################################\n","args.data_size = tokenizer.num_tokens\n","ntokens = args.data_size\n","model = model.RNNModel(args.model, ntokens, args.emsize, args.nhid, args.nlayers, args.dropout, args.tied)\n","print('* number of parameters: %d' % sum([p.nelement() for p in model.parameters()]))\n","if args.cuda:\n","    model.cuda()\n","\n","rnn_model = model\n","\n","optim = None\n","if args.load != '':\n","    sd = torch.load(args.load, map_location='cpu')\n","    if args.load_optim:\n","        optim_sd = torch.load(os.path.join(os.path.dirname(args.load), 'optim.pt'), map_location='cpu')\n","        rng = torch.load(os.path.join(os.path.dirname(args.load), 'rng.pt'))\n","        torch.cuda.set_rng_state(rng[0])\n","        torch.set_rng_state(rng[1])\n","    try:\n","        model.load_state_dict(sd)\n","    except:\n","        apply_weight_norm(model.rnn, hook_child=False)\n","        model.load_state_dict(sd)\n","        remove_weight_norm(model.rnn)\n","\n","if not args.no_weight_norm:\n","    apply_weight_norm(model, 'rnn', hook_child=False)\n","\n","# create optimizer and fp16 models\n","if args.fp16:\n","    model = FP16_Module(model)\n","    optim = eval('torch.optim.'+args.optim)(model.parameters(), lr=args.lr)\n","    optim = FP16_Optimizer(optim,\n","                           static_loss_scale=args.loss_scale,\t\n","                           dynamic_loss_scale=args.dynamic_loss_scale)\n","else:\n","    optim = eval('torch.optim.'+args.optim)(model.parameters(), lr=args.lr)\n","\n","if args.load_optim:\n","    pass\n","    optim.load_state_dict(optim_sd)\n","\n","# add linear learning rate scheduler\n","if train_data is not None:\n","    if args.constant_decay:\n","        num_iters = args.constant_decay\n","    else:\n","        num_iters = args.train_iters * args.epochs\n","\n","    init_step = -1\n","    if args.load_optim:\n","        init_step = optim_sd['iter']-optim_sd['skipped_iter']\n","        train_data.batch_sampler.start_iter = (optim_sd['iter'] % len(train_data)) + 1\n","\n","    LR = LinearLR(optim, num_iters, last_iter=init_step)\n","\n","# wrap model for distributed training\n","if args.world_size > 1:\n","    model = DDP(model)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","###############################################################################\n","# Training code\n","###############################################################################\n","\n","# get_batch subdivides the source data into chunks of length args.seq_length.\n","# If source is equal to the example output of the data loading example, with\n","# a seq_length limit of 2, we'd get the following two Variables for i = 0:\n","# ┌ a g m s ┐ ┌ b h n t ┐\n","# └ b h n t ┘ └ c i o u ┘\n","# Note that despite the name of the function, the subdivison of data is not\n","# done along the batch dimension (i.e. dimension 1), since that was handled\n","# by the data loader. The chunks are along dimension 0, corresponding\n","# to the seq_len dimension in the LSTM. A Variable representing an appropriate\n","# shard reset mask of the same dimensions is also returned.\n","\n","def get_batch(data):\n","    reset_mask_batch = data[1].long()\n","    data = data[0].long()\n","    if args.cuda:\n","        data = data.cuda()\n","        reset_mask_batch = reset_mask_batch.cuda()\n","    text_batch = Variable(data[:, :-1].t().contiguous(), requires_grad=False)\n","    target_batch = Variable(data[:, 1:].t().contiguous(), requires_grad=False)\n","    reset_mask_batch = Variable(reset_mask_batch[:,:text_batch.size(0)].t().contiguous(), requires_grad=False)\n","    return text_batch, target_batch, reset_mask_batch\n","\n","def init_hidden(batch_size):\n","    return rnn_model.rnn.init_hidden(args.batch_size)\n","\n","def evaluate(data_source, max_iters):\n","    # Turn on evaluation mode which disables dropout.\n","    model.eval()\n","    init_hidden(args.batch_size)\n","    total_loss = 0\n","    ntokens = args.data_size\n","    with torch.no_grad():\n","        data_iter = iter(data_source)\n","        i = 0\n","        while i < max_iters:\n","            batch = next(data_iter)\n","            data, targets, reset_mask = get_batch(batch)\n","            output, hidden = model(data, reset_mask=reset_mask)\n","            output_flat = output.view(-1, ntokens).contiguous().float()\n","            loss = criterion(output_flat, targets.view(-1).contiguous())\n","            if isinstance(model, DDP):\n","                torch.distributed.all_reduce(loss.data)\n","                loss.data /= args.world_size\n","            total_loss += loss.data[0]\n","            i += 1\n","    return total_loss / max(max_iters, 1)\n","\n","def train(max_iters, total_iters=0, skipped_iters=0, elapsed_time=False):\n","    # Turn on training mode which enables dropout.\n","    model.train()\n","    total_loss = 0\n","    start_time = time.time()\n","    t0 = start_time\n","    ntokens = args.data_size\n","    hidden = init_hidden(args.batch_size)\n","    curr_loss = 0.\n","    distributed = isinstance(model, DDP)\n","    def log(epoch, i, lr, ms_iter, total_time, loss, scale):\n","        print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:.2E} | ms/batch {:.3E} | total time {:.3E}\\\n","                  loss {:.2E} | ppl {:8.2f} | loss scale {:8.2f}'.format(\n","                      epoch, i, max_iters, lr,\n","                      ms_iter, total_time, loss, math.exp(min(loss, 20)), scale\n","                  )\n","        )\n","    data_iter = iter(train_data)\n","    i = 0\n","    while i < max_iters:\n","        batch = next(data_iter)\n","        data, targets, reset_mask = get_batch(batch)\n","        optim.zero_grad()\n","        output, hidden = model(data, reset_mask=reset_mask)\n","        loss = criterion(output.view(-1, ntokens).contiguous().float(), targets.view(-1).contiguous())\n","        total_loss += loss.data.float()\n","\n","        if args.fp16:\n","            optim.backward(loss, update_master_grads=False)\n","        else:\n","            loss.backward()\n","\n","        if distributed:\n","            torch.distributed.all_reduce(loss.data)\n","            loss.data /= args.world_size\n","            model.allreduce_params()\n","\n","        # clipping gradients helps prevent the exploding gradient problem in RNNs / LSTMs.\n","        if args.clip > 0:\n","            if not args.fp16:\n","                torch.nn.utils.clip_grad_norm(model.parameters(), args.clip)\n","            else:\n","                optim.clip_master_grads(clip=args.clip)\n","\n","        if args.fp16:\n","            optim.update_master_grads()\n","\n","        optim.step()\n","\n","        # step learning rate and log training progress\n","        lr = optim.param_groups[0]['lr']\n","        if not args.fp16:\n","            LR.step()\n","        else:\n","            # if fp16 optimizer skips gradient step due to explosion do not step lr\n","            if not optim.overflow:\n","                LR.step()\n","            else:\n","                skipped_iters += 1\n","\n","        # log current results\n","        if ((i+1) % args.log_interval == 0) and (i != max_iters - 1):\n","            cur_loss = total_loss[0] / args.log_interval\n","            cur_time = time.time()\n","            elapsed = cur_time - start_time\n","            total_elapsed = cur_time - t0 + elapsed_time\n","            log(epoch, i+1, lr, elapsed * 1000 / args.log_interval, total_elapsed, \n","                cur_loss, args.loss_scale if not args.fp16 else optim.loss_scale)\n","            total_loss = 0\n","            start_time = cur_time\n","            sys.stdout.flush()\n","\n","        # save current model progress. If distributed only save from worker 0\n","        if args.save_iters and total_iters % args.save_iters == 0 and total_iters > 0 and args.rank < 1:\n","            if args.rank < 1:\n","                with open(os.path.join(os.path.splitext(args.save)[0], 'e%s.pt'%(str(total_iters),)), 'wb') as f:\n","                    torch.save(model.state_dict(), f)\n","                if args.save_optim:\n","                    with open(os.path.join(os.path.splitext(args.save)[0], 'optim.pt'), 'wb') as f:\n","                        optim_sd = optim.state_dict()\n","                        optim_sd['iter'] = total_iters\n","                        optim_sd['skipped_iter'] = skipped_iters\n","                        torch.save(optim_sd, f)\n","                        del optim_sd\n","\n","                    with open(os.path.join(os.path.splitext(args.save)[0], 'rng.pt'), 'wb') as f:\n","                        torch.save((torch.cuda.get_rng_state(), torch.get_rng_state()),f)\n","            if args.cuda:\n","                torch.cuda.synchronize()\n","        total_iters += 1\n","        i += 1\n","    #final logging\n","    elapsed_iters = max_iters % args.log_interval\n","    if elapsed_iters == 0:\n","        elapsed_iters = args.log_interval\n","    cur_loss = total_loss[0] / elapsed_iters\n","    cur_time = time.time()\n","    elapsed = cur_time - start_time\n","    total_elapsed = cur_time - t0 + elapsed_time\n","    log(epoch, max_iters, lr, elapsed * 1000/ elapsed_iters, total_elapsed,\n","        cur_loss, args.loss_scale if not args.fp16 else optim.loss_scale)\n","\n","    return cur_loss, skipped_iters\n","\n","# Loop over epochs.\n","lr = args.lr\n","best_val_loss = None\n","\n","# If saving process intermittently create directory for saving\n","if args.save_iters > 0 and not os.path.exists(os.path.splitext(args.save)[0]) and args.rank < 1:\n","    os.makedirs(os.path.splitext(args.save)[0])\n","\n","# At any point you can hit Ctrl + C to break out of training early.\n","try:\n","    total_iters = 0\n","    elapsed_time = 0\n","    skipped_iters = 0\n","    if args.load_optim:\n","        total_iters = optim_sd['iter']\n","        skipped_iters = optim_sd['skipped_iter']\n","    for epoch in range(1, args.epochs+1):\n","        epoch_start_time = time.time()\n","        val_loss, skipped_iters = train(args.train_iters, total_iters, skipped_iters, elapsed_time)\n","        elapsed_time += time.time() - epoch_start_time\n","        total_iters += args.train_iters\n","        if val_data is not None:\n","            print('entering eval')\n","            val_loss = evaluate(val_data, args.eval_iters)\n","        print('-' * 89)\n","        print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n","              'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n","                                         val_loss, math.exp(min(val_loss, 20))))\n","        print('-' * 89)\n","        # Save the model if the validation loss is the best we've seen so far.\n","        if not best_val_loss or val_loss < best_val_loss and args.rank <= 0:\n","            torch.save(model.state_dict(), args.save)\n","            best_val_loss = val_loss\n","\n","except KeyboardInterrupt:\n","    print('-' * 89)\n","    print('Exiting from training early')\n","\n","# Load the best saved model.\n","if os.path.exists(args.save):\n","    model.load_state_dict(torch.load(args.save, 'cpu'))\n","\n","if not args.no_weight_norm and args.rank <= 0:\n","    remove_weight_norm(rnn_model)\n","    with open(args.save, 'wb') as f:\n","        torch.save(model.state_dict(), f)\n","\n","if test_data is not None:\n","    # Run on test data.\n","    test_loss = evaluate(test_data, args.eval_iters)\n","    print('=' * 89)\n","    print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n","        test_loss, math.exp(test_loss)))\n","    print('=' * 89)\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-1f426a54bf91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfp16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFP16_Module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFP16_Optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fp16'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"J_Vn7_aL4neE","colab_type":"code","outputId":"2ae3c132-1686-4eb2-ab33-917765e2d0db","executionInfo":{"status":"ok","timestamp":1572397538114,"user_tz":420,"elapsed":2302,"user":{"displayName":"Mugi Chan","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBpKG-YT6RM9PqmC6bEpu2enF_2KoNB9f1f-EHT=s64","userId":"05673157240922939125"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jD53verak9vP","colab_type":"code","outputId":"b502b9b3-0210-4c2a-debd-4289f90354f4","executionInfo":{"status":"ok","timestamp":1572397547458,"user_tz":420,"elapsed":8923,"user":{"displayName":"Mugi Chan","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBpKG-YT6RM9PqmC6bEpu2enF_2KoNB9f1f-EHT=s64","userId":"05673157240922939125"}},"colab":{"base_uri":"https://localhost:8080/","height":595}},"source":["import pandas as pd\n","import numpy as np\n","import nltk \n","nltk.download()\n","#tokenizers: word tokenizers(split by words) / sentence tokenizers(split by sent.)\n","#lexicon & corporas \n","#corporas: body of text, e.g, long texts, anything in english language\n","#lexicon:  words and their meanings. \"dictionary\"\n","#          investor language vs. english language (investors have their own set of language)\n","#stopwords: words that we want to exclude. e.g \"a\", \"the\", \"and\"\n","\n","  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["NLTK Downloader\n","---------------------------------------------------------------------------\n","    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n","---------------------------------------------------------------------------\n","Downloader> l\n","\n","Packages:\n","  [*] abc................. Australian Broadcasting Commission 2006\n","  [*] alpino.............. Alpino Dutch Treebank\n","  [*] averaged_perceptron_tagger Averaged Perceptron Tagger\n","  [*] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n","  [*] basque_grammars..... Grammars for Basque\n","  [*] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n","                           Extraction Systems in Biology)\n","  [*] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n","  [*] book_grammars....... Grammars from NLTK Book\n","  [*] brown............... Brown Corpus\n","  [*] brown_tei........... Brown Corpus (TEI XML Version)\n","  [*] cess_cat............ CESS-CAT Treebank\n","  [*] cess_esp............ CESS-ESP Treebank\n","  [*] chat80.............. Chat-80 Data Files\n","  [*] city_database....... City Database\n","  [*] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n","  [*] comparative_sentences Comparative Sentence Dataset\n","  [*] comtrans............ ComTrans Corpus Sample\n","  [*] conll2000........... CONLL 2000 Chunking Corpus\n","  [*] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n","Hit Enter to continue: q\n","\n","---------------------------------------------------------------------------\n","    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n","---------------------------------------------------------------------------\n","Downloader> q\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"EKsIDye2UYhW","colab_type":"code","colab":{}},"source":["from nltk.tokenize import word_tokenize #creates a list #word_tokenize treats punctuations as \"words\"\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from nltk.corpus import wordnet\n","from nltk.stem import WordNetLemmatizer \n","from nltk.tag import pos_tag\n","ps=PorterStemmer()\n","lemmatizer=WordNetLemmatizer()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sbyadWbjLwyq","colab_type":"code","outputId":"ef0be49a-2b56-47d2-f3d2-8ac08d473102","executionInfo":{"status":"ok","timestamp":1572397551726,"user_tz":420,"elapsed":909,"user":{"displayName":"Mugi Chan","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBpKG-YT6RM9PqmC6bEpu2enF_2KoNB9f1f-EHT=s64","userId":"05673157240922939125"}},"colab":{"base_uri":"https://localhost:8080/","height":340}},"source":["news_data= pd.read_csv(\"/content/drive/My Drive/CS3244/Colab/datasets/google_facebook_microsoft_news.csv\") \n","news_data.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>date</th>\n","      <th>open</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>close</th>\n","      <th>volume</th>\n","      <th>Name</th>\n","      <th>main_news</th>\n","      <th>tagged_news</th>\n","      <th>target_reg</th>\n","      <th>target_class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2013-02-08</td>\n","      <td>390.4551</td>\n","      <td>393.7283</td>\n","      <td>390.1698</td>\n","      <td>393.0777</td>\n","      <td>6031199</td>\n","      <td>GOOGL</td>\n","      <td>Google Changes Its Ad Program to Try to Solve ...</td>\n","      <td>NaN</td>\n","      <td>391.2659</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>2013-02-13</td>\n","      <td>390.4551</td>\n","      <td>393.0677</td>\n","      <td>390.3750</td>\n","      <td>391.8214</td>\n","      <td>2393946</td>\n","      <td>GOOGL</td>\n","      <td>Lost in Translation? Try a Google App: Google’...</td>\n","      <td>NaN</td>\n","      <td>394.0937</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7</td>\n","      <td>2013-02-20</td>\n","      <td>403.0527</td>\n","      <td>404.8895</td>\n","      <td>396.2929</td>\n","      <td>396.6262</td>\n","      <td>5522500</td>\n","      <td>GOOGL</td>\n","      <td>Google Will Offer Its Glasses to Select Few: G...</td>\n","      <td>NaN</td>\n","      <td>400.0296</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>8</td>\n","      <td>2013-02-21</td>\n","      <td>399.3990</td>\n","      <td>403.1277</td>\n","      <td>396.0056</td>\n","      <td>398.1628</td>\n","      <td>7008464</td>\n","      <td>GOOGL</td>\n","      <td>Google Searches for Style: As Google and other...</td>\n","      <td>Tip of the Week: Search the Text on a Web Page...</td>\n","      <td>401.5512</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10</td>\n","      <td>2013-02-25</td>\n","      <td>401.5512</td>\n","      <td>404.6092</td>\n","      <td>395.6402</td>\n","      <td>395.7804</td>\n","      <td>4602925</td>\n","      <td>GOOGL</td>\n","      <td>Q&amp;A: Recommending Web Pages With the Google +1...</td>\n","      <td>NaN</td>\n","      <td>397.7974</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0        date  ...  target_reg  target_class\n","0           0  2013-02-08  ...    391.2659         False\n","1           3  2013-02-13  ...    394.0937          True\n","2           7  2013-02-20  ...    400.0296          True\n","3           8  2013-02-21  ...    401.5512          True\n","4          10  2013-02-25  ...    397.7974          True\n","\n","[5 rows x 12 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"UhA9B9sh40hI","colab_type":"code","outputId":"00b51f64-d232-4a53-8304-a23b9614e3b5","executionInfo":{"status":"ok","timestamp":1572397672188,"user_tz":420,"elapsed":1271,"user":{"displayName":"Mugi Chan","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBpKG-YT6RM9PqmC6bEpu2enF_2KoNB9f1f-EHT=s64","userId":"05673157240922939125"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["\n","#stopwords\n","stop_words=set(stopwords.words(\"english\")) #a set of predefined english stopwords\n","#any words we want to add stop_words.add()\n","\n","#tokenising newsheadline\n","\n","\n","\n","# news_data.shape[0]\n","#keep punctuations?\n","for i in range(10):\n","  tokens=[]\n","  filtered_tokens=[]\n","  final = \" \"\n","  if(type(news_data.loc[i,'main_news'])==float):\n","    news_data.loc[i,'filtered'] =final\n","  else:\n","    tokens.append((word_tokenize(news_data.loc[i,'main_news'])))\n","    #filter &stem tokens\n","    for w in tokens[0]:\n","      if w not in stop_words:\n","        result=pos_tag([w])\n","        if result[0][1].startswith('J'):\n","            tag=wordnet.ADJ\n","        elif result[0][1].startswith('V'):\n","            tag=wordnet.VERB\n","        elif result[0][1].startswith('N'):\n","            tag=wordnet.NOUN\n","        elif result[0][1].startswith('R'):\n","            tag=wordnet.ADV\n","        else:\n","            tag=wordnet.NOUN\n","        filtered_tokens.append(lemmatizer.lemmatize(word=result[0][0],pos=tag))                      \n","    for j in filtered_tokens:\n","      final+=j\n","      final+= \" \"\n","    print(final)\n","    news_data.loc[i,'filtered'] =final\n","  \n","\n","  \n","# Google Changes Its Ad Program to Try to Solve the Mobile Ad Riddle: Google made the biggest change to its AdWords program in years, forcing advertisers onto mobile devices and raising protests from some digital ad companies.\n","Lost in Translation? Try a Google App: Google’s Translate app proves its worth on a trip to China. But knowing your way around it in advance is a good idea.\n","\n","  \n"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" Google Changes Its Ad Program Try Solve Mobile Ad Riddle : Google make big change AdWords program year , force advertiser onto mobile device raise protest digital ad company . \n"," Lost Translation ? Try Google App : Google ’ Translate app prof worth trip China . But know way around advance good idea . \n"," Google Will Offer Its Glasses Select Few : Google make Glass , augment reality glass , available people apply , chosen willing pay $ 1,500 try . \n"," Google Searches Style : As Google company begin build wearable technology device , industry know fashion sense face new challenge . \n"," Q & A : Recommending Web Pages With Google +1 Button : Google ’ “ +1″ button another way express public admiration Web page . \n"," The Original Search Engine : In day Google , New York Public Library hand clipped hundred thousand photo illustration create 12,000 different file Picture Collection . \n"," What Is Point Google ’ Chromebook Pixel ? : Google ’ late offering , Chromebook Pixel , bit baffling . \n"," German Copyright Law Targets Google Links : A bill broadening protection news publisher approve German lawmaker , critic say measure go far enough . \n"," Q & A : Checking Web Site ’ Security : Google Chrome browser warn something seem right Web site ’ security credential . \n"," In Upgrade , Google Adds Model Mobile Marketing : Google bring three new brand digital advertising initiative , attempt get marketer think technology best asset . \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KLnOLBBp70ny","colab_type":"code","outputId":"b8f36f5e-34c1-4daa-834f-4c53d6ee64ca","executionInfo":{"status":"error","timestamp":1571766485481,"user_tz":420,"elapsed":4363,"user":{"displayName":"Mugi Chan","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBpKG-YT6RM9PqmC6bEpu2enF_2KoNB9f1f-EHT=s64","userId":"05673157240922939125"}},"colab":{"base_uri":"https://localhost:8080/","height":715}},"source":["! pip install vaderSentiment\n","\n","from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer as SA\n","\n","sa=SA()\n","\n","for i in range(news_data.shape[0]): \n","    if news_data['filtered'][i]== \"\":\n","      pol_score=0\n","    else:\n","      pol_score = sa.polarity_scores(news_data['filtered'][i])\n","    news_headline['score_F']=pol_score\n","    \n","\n","news_data['Sentiments_filtered'] = 0\n","news_data.loc[i, 'Sentiments_filtered'][news_data.loc[i, 'score_F']>0.1] = 1 #change 0.2?\n","news_data.loc[i, 'Sentiments_filtered'][news_data.loc[i, 'score_F']<-0.1] = -1\n","\n","\n","for i in range(news_data.shape[0]): \n","    if news_data['main_news'][i]== \"\":\n","      pol_score=0\n","    else:\n","      pol_score = sa.polarity_scores(news_data['news'][i])\n","    news_data['score_R']=pol_score\n","    \n","news_data['Sentiments_raw'] = 0\n","news_data.loc[i, 'Sentiments_raw'][news_data.loc[i, 'score_R']>0.1] = 1 #change 0.2?\n","news_data.loc[i, 'Sentiments_raw'][news_data.loc[i, 'score_R']<-0.1] = -1\n","\n","#headlines here are as strings\n","#join previous headlines df with date and everything to scores? \n","## results = pd.DataFrame(columns=['Company','Score','Date'])\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.6/dist-packages (3.2.1)\n"],"name":"stdout"},{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'filtered'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-255f49f8d7c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnews_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mnews_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filtered'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m       \u001b[0mpol_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'filtered'"]}]},{"cell_type":"code","metadata":{"id":"T4rrI81FRnbr","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XU_hce_eGCjf","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}